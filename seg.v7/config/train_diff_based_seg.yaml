base_config:
- config/logging.yaml
- config/wandb.yaml

- config/dataset/dataset_train.yaml
- config/dataset/dataset_val.yaml
- config/dataset/dataset_vis.yaml
- config/model_sdv2.yaml


pipeline:
  name: diff_based_seg_pipeline
  kwargs:

augmentation:
  lr_flip_p: 0.5

dataloader:
  num_workers: 2 # original:2
  effective_batch_size: 48 # original:32
  max_train_batch_size: 3 # original:2
  seed: 2024  # to ensure continuity when resuming from checkpoint

# Training settings
trainer:
  name: DiffBasedSegTrainer
  training_noise_scheduler:
    pretrained_path: stable-diffusion-2
  init_seed: 2024  # use null to train w/o seeding
  save_period: 50
  backup_period: 1000
  validation_period: 10
  visualization_period: 500

multi_res_noise:
  strength: 0.9
  annealed: true
  downscale_strategy: original

gt_seg_type: seg_norm

max_epoch: 1000  # a large enough number 10000
max_iter: 31000  # usually converges at around 20k 30000

optimizer:
  name: Adam

loss:
  name: crossentropy_loss
  kwargs:
    reduction: mean

lr: 3.0e-05
lr_scheduler:
  name: IterExponential
  kwargs:
    total_iter: 25000
    final_ratio: 0.01
    warmup_steps: 100

# Validation (and visualization) settings
validation:
  denoising_steps: 50
  ensemble_size: 1  # simplified setting for on-training validation
  processing_res: 0
  match_input_res: false
  resample_method: bilinear
  main_val_metric: mIoU
  main_val_metric_goal: maxmize
  init_seed: 2024

eval:
  eval_metrics:
  - mIoU